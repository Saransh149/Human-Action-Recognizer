{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/coderpython/saransh-rajpurohit-celebal-project?scriptVersionId=139415497\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import os\nimport glob\nimport random\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow_addons as tfa\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Activation, Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom tqdm import tqdm\n\nfrom PIL import Image\n\nfrom tensorflow.keras.utils import to_categorical\n\nimport seaborn as sns\nimport matplotlib.image as img\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-07-26T15:16:52.136625Z","iopub.execute_input":"2023-07-26T15:16:52.136983Z","iopub.status.idle":"2023-07-26T15:17:01.018919Z","shell.execute_reply.started":"2023-07-26T15:16:52.136952Z","shell.execute_reply":"2023-07-26T15:17:01.01757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv = pd.read_csv(\"../input/human-action-recognition-har-dataset/Human Action Recognition/Training_set.csv\")\ntest_csv = pd.read_csv(\"../input/human-action-recognition-har-dataset/Human Action Recognition/Testing_set.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-07-26T15:17:01.021174Z","iopub.execute_input":"2023-07-26T15:17:01.021849Z","iopub.status.idle":"2023-07-26T15:17:01.064639Z","shell.execute_reply.started":"2023-07-26T15:17:01.021812Z","shell.execute_reply":"2023-07-26T15:17:01.063745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_fol = glob.glob(\"../input/human-action-recognition-har-dataset/Human Action Recognition/train/*\") \ntest_fol = glob.glob(\"../input/human-action-recognition-har-dataset/Human Action Recognition/test/*\")","metadata":{"execution":{"iopub.status.busy":"2023-07-26T15:17:01.065911Z","iopub.execute_input":"2023-07-26T15:17:01.066246Z","iopub.status.idle":"2023-07-26T15:17:02.314187Z","shell.execute_reply.started":"2023-07-26T15:17:01.066212Z","shell.execute_reply":"2023-07-26T15:17:02.313159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-07-26T15:17:02.317484Z","iopub.execute_input":"2023-07-26T15:17:02.318446Z","iopub.status.idle":"2023-07-26T15:17:02.338626Z","shell.execute_reply.started":"2023-07-26T15:17:02.3184Z","shell.execute_reply":"2023-07-26T15:17:02.337525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv","metadata":{"execution":{"iopub.status.busy":"2023-07-26T15:17:02.339977Z","iopub.execute_input":"2023-07-26T15:17:02.340709Z","iopub.status.idle":"2023-07-26T15:17:02.35692Z","shell.execute_reply.started":"2023-07-26T15:17:02.340676Z","shell.execute_reply":"2023-07-26T15:17:02.355867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = train_csv['filename']\nsituation = train_csv['label']","metadata":{"execution":{"iopub.status.busy":"2023-07-26T15:17:02.358482Z","iopub.execute_input":"2023-07-26T15:17:02.359014Z","iopub.status.idle":"2023-07-26T15:17:02.364052Z","shell.execute_reply.started":"2023-07-26T15:17:02.358965Z","shell.execute_reply":"2023-07-26T15:17:02.362957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgg = \"Image_{}.jpg\".format(1)\ntrain = \"../input/human-action-recognition-har-dataset/Human Action Recognition/train/\"\ntestImage = img.imread(train + imgg)\nplt.imshow(testImage)\nplt.title(\"{}\".format(train_csv.loc[train_csv['filename'] == \"{}\".format(imgg), 'label'].item()))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-26T15:17:02.365908Z","iopub.execute_input":"2023-07-26T15:17:02.366281Z","iopub.status.idle":"2023-07-26T15:17:02.786891Z","shell.execute_reply.started":"2023-07-26T15:17:02.366236Z","shell.execute_reply":"2023-07-26T15:17:02.786041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  **Pre Processing**","metadata":{}},{"cell_type":"code","source":"img_data = []\nimg_label = []\nlength = len(train_fol)\nfor i in (range(len(train_fol)-1)):\n    t = '../input/human-action-recognition-har-dataset/Human Action Recognition/train/' + filename[i]    \n    temp_img = Image.open(t)\n    img_data.append(np.asarray(temp_img.resize((160,160))))\n    img_label.append(situation[i])","metadata":{"execution":{"iopub.status.busy":"2023-07-26T15:17:02.787841Z","iopub.execute_input":"2023-07-26T15:17:02.788155Z","iopub.status.idle":"2023-07-26T15:18:31.71401Z","shell.execute_reply.started":"2023-07-26T15:17:02.788123Z","shell.execute_reply":"2023-07-26T15:18:31.712988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inp_shape = (160, 160,3)","metadata":{"execution":{"iopub.status.busy":"2023-07-26T15:18:31.717965Z","iopub.execute_input":"2023-07-26T15:18:31.718257Z","iopub.status.idle":"2023-07-26T15:18:31.724256Z","shell.execute_reply.started":"2023-07-26T15:18:31.718233Z","shell.execute_reply":"2023-07-26T15:18:31.72325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"arr = img_data\narr = np.asarray(arr)\ntype(arr)","metadata":{"execution":{"iopub.status.busy":"2023-07-26T15:18:31.728738Z","iopub.execute_input":"2023-07-26T15:18:31.72902Z","iopub.status.idle":"2023-07-26T15:18:32.033928Z","shell.execute_reply.started":"2023-07-26T15:18:31.728996Z","shell.execute_reply":"2023-07-26T15:18:32.032814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = to_categorical(np.asarray(train_csv['label'].factorize()[0]))\nprint(y_train[0])","metadata":{"execution":{"iopub.status.busy":"2023-07-26T15:18:32.035747Z","iopub.execute_input":"2023-07-26T15:18:32.036118Z","iopub.status.idle":"2023-07-26T15:18:32.047449Z","shell.execute_reply.started":"2023-07-26T15:18:32.036084Z","shell.execute_reply":"2023-07-26T15:18:32.046387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_model = Sequential()\n\npretrained_model= tf.keras.applications.VGG16(include_top=False,\n                   input_shape=(160,160,3),\n                   pooling='avg',classes=15,\n                   weights='imagenet')\n\nfor layer in pretrained_model.layers:\n        layer.trainable=False\n\nvgg_model.add(pretrained_model)\nvgg_model.add(Flatten())\nvgg_model.add(Dense(512, activation='relu'))\nvgg_model.add(Dense(15, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2023-07-26T15:18:32.049467Z","iopub.execute_input":"2023-07-26T15:18:32.050233Z","iopub.status.idle":"2023-07-26T15:18:35.951663Z","shell.execute_reply.started":"2023-07-26T15:18:32.050196Z","shell.execute_reply":"2023-07-26T15:18:35.950691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-07-26T15:18:35.953Z","iopub.execute_input":"2023-07-26T15:18:35.953353Z","iopub.status.idle":"2023-07-26T15:18:35.973373Z","shell.execute_reply.started":"2023-07-26T15:18:35.953303Z","shell.execute_reply":"2023-07-26T15:18:35.972469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-26T15:18:35.974621Z","iopub.execute_input":"2023-07-26T15:18:35.975194Z","iopub.status.idle":"2023-07-26T15:18:35.995547Z","shell.execute_reply.started":"2023-07-26T15:18:35.975161Z","shell.execute_reply":"2023-07-26T15:18:35.994802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = vgg_model.fit(arr,y_train, epochs=40)","metadata":{"execution":{"iopub.status.busy":"2023-07-26T15:18:35.996743Z","iopub.execute_input":"2023-07-26T15:18:35.997062Z","iopub.status.idle":"2023-07-26T15:29:01.019763Z","shell.execute_reply.started":"2023-07-26T15:18:35.997031Z","shell.execute_reply":"2023-07-26T15:29:01.018726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_model.save_weights(\"model.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-07-26T15:29:01.021518Z","iopub.execute_input":"2023-07-26T15:29:01.021902Z","iopub.status.idle":"2023-07-26T15:29:01.172226Z","shell.execute_reply.started":"2023-07-26T15:29:01.021866Z","shell.execute_reply":"2023-07-26T15:29:01.171184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accurate = history.history['accuracy']\nplt.plot(accurate)","metadata":{"execution":{"iopub.status.busy":"2023-07-26T15:29:01.173884Z","iopub.execute_input":"2023-07-26T15:29:01.174231Z","iopub.status.idle":"2023-07-26T15:29:01.46342Z","shell.execute_reply.started":"2023-07-26T15:29:01.174197Z","shell.execute_reply":"2023-07-26T15:29:01.462301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Inference Pipeline**","metadata":{}},{"cell_type":"code","source":"def test_predict(test_image):\n    situation=[\"sitting\",\"using_laptop\",\"hugging\",\"sleeping\",\"drinking\",\n           \"clapping\",\"dancing\",\"cycling\",\"calling\",\"laughing\"\n          ,\"eating\",\"fighting\",\"listening_to_music\",\"running\",\"texting\"]\n    image = Image.open(test_image)\n    input_img = np.asarray(image.resize((160,160)))\n    result = vgg_model.predict(np.asarray([input_img]))\n\n    itemindex = np.where(result==np.max(result))\n    prediction = itemindex[1][0]\n    print(\"probability: \"+str(np.max(result)*100) + \"%\\nPredicted class : \", situation[prediction])\n\n    image = img.imread(test_image)\n    plt.imshow(image)\n ","metadata":{"execution":{"iopub.status.busy":"2023-07-26T15:29:01.464966Z","iopub.execute_input":"2023-07-26T15:29:01.465325Z","iopub.status.idle":"2023-07-26T15:29:01.473364Z","shell.execute_reply.started":"2023-07-26T15:29:01.465291Z","shell.execute_reply":"2023-07-26T15:29:01.472128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predict('../input/human-action-recognition-har-dataset/Human Action Recognition/test/Image_50.jpg')","metadata":{"execution":{"iopub.status.busy":"2023-07-26T15:31:28.789453Z","iopub.execute_input":"2023-07-26T15:31:28.789818Z","iopub.status.idle":"2023-07-26T15:31:29.305889Z","shell.execute_reply.started":"2023-07-26T15:31:28.789789Z","shell.execute_reply":"2023-07-26T15:31:29.303141Z"},"trusted":true},"execution_count":null,"outputs":[]}]}